
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Main: Msg: Starting intervention mode 1 on layer 0
/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/tensorly/backend/pytorch_backend.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(
Main: Msg: Edited and put modl on device in time 6 second
  0%|                                                                                                                                                                                                           | 0/18812 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 266, in __getattr__
    return self.data[item]
           ~~~~~~~~~^^^^^^
KeyError: 'dtype'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/data/home/hpate061/Laser_T/src/TASER_intervention_gptj_bbh_qa.py", line 275, in <module>
    predictions = experiment.intervene(model=model,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/hpate061/Laser_T/src/TASER_intervention_gptj_bbh_qa.py", line 87, in intervene
    inputs = tokenizer(prompt, return_tensors="pt").to(self.device).dtype(model_edit.dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 268, in __getattr__
    raise AttributeError
AttributeError