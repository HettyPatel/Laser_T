
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "/data/home/hpate061/Laser_T/src/TASER_intervention_gptj_bbh_qa.py", line 275, in <module>
    predictions = experiment.intervene(model=model,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/hpate061/Laser_T/src/TASER_intervention_gptj_bbh_qa.py", line 68, in intervene
    model_edit = GPTJTaser.get_edited_model(model=model, intervention_mode=intervention_mode, layer=layer, rank=rank, decomposition_type=decomposition_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/hpate061/Laser_T/src/taser/gptj_taser.py", line 110, in get_edited_model
    reconstructed_tensor = GPTJTaser.return_reconstructed_tensor(stacked_tensor, decomposition_type, rank)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/hpate061/Laser_T/src/taser/gptj_taser.py", line 223, in return_reconstructed_tensor
    raise AssertionError(f"Unhandled decomposition type {decomp_type}")
AssertionError: Unhandled decomposition type 1
Main: Msg: Starting intervention mode 1 on layer 0