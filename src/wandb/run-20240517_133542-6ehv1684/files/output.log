
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/tensorly/backend/pytorch_backend.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(
Main: Msg: Starting intervention mode 1 on layer 0
  0%|                                                                                                                                                                                                                                                                                                                                                                                                              | 0/74 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
  0%|                                                                                                                                                                                                                                                                                                                                                                                                              | 0/74 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/data/home/hpate061/Laser_T/src/TASER_intervention_gptj_bbh_qa.py", line 285, in <module>
    predictions = experiment.intervene(model=model,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/hpate061/Laser_T/src/TASER_intervention_gptj_bbh_qa.py", line 92, in intervene
    generate_ids = model_edit.generate(inputs.input_ids, max_new_tokens=10, min_new_tokens=1)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/transformers/generation/utils.py", line 1606, in generate
    return self.greedy_search(
           ^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/transformers/generation/utils.py", line 2454, in greedy_search
    outputs = self(
              ^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py", line 855, in forward
    transformer_outputs = self.transformer(
                          ^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py", line 690, in forward
    outputs = block(
              ^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py", line 308, in forward
    hidden_states = self.ln_1(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/modules/normalization.py", line 196, in forward
    return F.layer_norm(
           ^^^^^^^^^^^^^
  File "/home/hpate061/anaconda3/envs/Research/lib/python3.11/site-packages/torch/nn/functional.py", line 2543, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Main: Msg: Edited and put model on device in time 6 second